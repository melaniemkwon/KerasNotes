{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch 2 - Mathematical Building Blocks of Neural Networks\n",
    "\n",
    "From https://github.com/fchollet/deep-learning-with-python-notebooks,\n",
    "combined with my own notes from the book.\n",
    "\n",
    "### 2.1 First example of a neural network\n",
    "\n",
    "The problem we’re trying to solve here is to classify grayscale images of handwritten digits (28 × 28 pixels) into their 10 categories (0 through 9). We’ll use the MNIST dataset, a classic in the machine-learning community, which has been around almost as long as the field itself and has been intensively studied. It’s a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melaniekwon/Dropbox/School/THESIS/tensorflowPractice/venv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/melaniekwon/Dropbox/School/THESIS/tensorflowPractice/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset comes preloaded in Keras\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Present our neural network with the training data, train_images and train_labels. \n",
    "2. The network will then learn to associate images and labels.\n",
    "3. Ask the network to produce predictions for test_images, and we will verify if these predictions match the labels from test_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "network consists of a chain of two Dense layers, that each layer applies a few simple tensor \n",
    "operations to the input data, and that these operations involve weight tensors. \n",
    "Weight tensors, which are attributes of the layers, are where the knowledge of the network persists.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence of two Dense layers, which are densely-connected (also called \"fully-connected\") neural layers.\n",
    "\n",
    "The second (and last) layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1).\n",
    "\n",
    "Each score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
    "\n",
    "---\n",
    "\n",
    "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
    "\n",
    "- **A loss function:** the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be able to steer itself in the right direction.\n",
    "- **An optimizer:** this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "- **Metrics to monitor during training and testing:** Here we will only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Categorical_crossentropy is the loss function that’s used as a feedback signal for learning \n",
    "the weight tensors, and which the training phase will attempt to minimize.\n",
    "this reduction of the loss happens via mini-batch stochastic gradient descent. \n",
    "\n",
    "The exact rules governing a specific use of gradient descent are defined by the rmsprop \n",
    "optimizer passed as the first argument\n",
    "'''\n",
    "\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "\n",
    "Preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the [0, 1] interval.\n",
    "\n",
    "**Training image**\n",
    "\n",
    "Before: array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval\n",
    "\n",
    "After: float32 array of shape (60000, 28 * 28) with values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "input images are stored in Numpy tensors, which are here formatted as float32 tensors of shape \n",
    "(60000, 784) (training data) and (10000, 784) (test data)\n",
    "'''\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorically encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "\n",
    "We are now ready to train our network, which in Keras is done via a call to the fit method of the network: we \"fit\" the model to its training data.\n",
    "\n",
    "The network will start to iterate on the training data in mini-batches of 128 samples, 5 times over (each iteration over all the training data is called an epoch). At each iteration, the network will compute the gradients of the weights with regard to the loss on the batch, and update the weights accordingly. After these 5 epochs, the network will have performed 2,345 gradient updates (469 per epoch), and the loss of the network will be sufficiently low that the network will be capable of classifying handwritten digits with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.2597 - acc: 0.9253\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1031 - acc: 0.9696\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0689 - acc: 0.9792\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0498 - acc: 0.9847\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0380 - acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x107ff57b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are being displayed during training: \n",
    "- the \"loss\" of the network over the training data, and \n",
    "- the accuracy of the network over the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 91us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data Representations for Neural Networks\n",
    "\n",
    "In the previous example, we started from data stored in multidimensional Numpy arrays, also called tensors. In general, all current machine-learning systems use tensors as their basic data structure. Tensors are fundamental to the field—so fundamental that Google’s TensorFlow was named after them. So what’s a tensor?\n",
    "\n",
    "At its core, a tensor is a container for data—almost always numerical data. So, it’s a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions (note that in the context of tensors, a *dimension* is often called an *axis*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalars (0D tensors)\n",
    "\n",
    "A tensor that contains only one number is called a **scalar** (or scalar tensor, or 0-dimensional tensor, or 0D tensor). \n",
    "\n",
    "In Numpy, a float32 or float64 number is a scalar tensor (or scalar array). \n",
    "\n",
    "Display the number of axes of a Numpy tensor via the `ndim` attribute; a scalar tensor has 0 axes (ndim == 0).  \n",
    "\n",
    "The number of axes of a tensor is also called its *rank*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectors (1D tensors)\n",
    "\n",
    "An array of numbers is called a vector, or 1D tensor. A 1D tensor is said to have exactly one axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices (2D tensors)\n",
    "\n",
    "An array of vectors is a matrix, or 2D tensor. A matrix has two axes (often referred to rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "                  [6, 79, 3, 35, 1],\n",
    "                  [7, 80, 4, 36, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D tensors and higher-dimensional tensors\n",
    "\n",
    "If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually interpret as a cube of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "                   [6, 79, 3, 35, 1],\n",
    "                   [7, 80, 4, 36, 2]],\n",
    "                  [[5, 78, 2, 34, 0],\n",
    "                   [6, 79, 3, 35, 1],\n",
    "                   [7, 80, 4, 36, 2]],\n",
    "                  [[5, 78, 2, 34, 0],\n",
    "                   [6, 79, 3, 35, 1],\n",
    "                   [7, 80, 4, 36, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key attributes\n",
    "\n",
    "A tensor is defined by three key attributes:\n",
    "1. **Number of axes (rank)**\n",
    "2. **Shape** - tuple of integers that describes how many dimensions the tensor has along each axis\n",
    "3. **Data type** - the type of the data contained in the tensor; for instance, a tensor’s type could be float32, uint8, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "'''Going back to MNIST'''\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.ndim)   # number of axes/rank\n",
    "print(train_images.shape)  # its shape\n",
    "print(train_images.dtype)  # data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D tensor of 8-bit integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUP8HF8NDxhA0MHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125d2a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors in Numpy\n",
    "\n",
    "Selecting specific elements in a tensor is called *tensor slicing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "selects digits #10 to #100 (#100 isn’t included) and \n",
    "puts them in an array of shape (90, 28, 28)\n",
    "'''\n",
    "\n",
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to above\n",
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also equivalent\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, you may *select between any two indices along each tensor axis*. \n",
    "\n",
    "For instance, in order to select 14 × 14 pixels in the bottom-right corner of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The notion of data batches\n",
    "\n",
    "the first axis (axis 0, because indexing starts at 0) in all data tensors you’ll come across in deep learning will be the *samples axis* (samples dimension).\n",
    "\n",
    "Deep-learning models don’t process an entire dataset at once; rather, they break the data into small batches. Concretely, here’s one batch of our MNIST digits, with batch size of 128:\n",
    "\n",
    "`batch = train_images[:128]`\n",
    "\n",
    "`batch = train_images[128:256]`\n",
    "\n",
    "`batch = train_images[128 * n:128 * (n + 1)]`\n",
    "\n",
    "When considering such a batch tensor, the first axis (axis 0) is called the batch axisor batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world examples of data tensors\n",
    "\n",
    "The data you’ll manipulate will almost always fall into one of the following categories:\n",
    "\n",
    "- **Vector data**— 2D tensors of shape (samples, features)\n",
    "- **Timeseries data or sequence data**— 3D tensors of shape (samples, timesteps, features)\n",
    "- **Images**— 4D tensors of shape (samples, height, width, channels) or (samples, channels, height, width)\n",
    "- **Video**— 5D tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector data\n",
    "\n",
    "This is the most common case. In such a dataset, each single data point can be encoded as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of vectors), where the first axis is the *samples axis* and the second axis is the *features axis*.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- An actuarial dataset of people, where we consider each person’s age, ZIP code, and income. Each person can be characterized as a vector of 3 values. So the entire dataset of 100,000 people can be stored in a 2D tensor of shape (100000, 3).\n",
    "- A dataset of text documents, where we represent each document by the counts of how many times each word appears in it (out of a dictionary of 20,000 common words). Each document can be encoded as a vector of 20,000 values (one count per word in the dictionary), and thus an entire dataset of 500 documents can be stored in a tensor of shape (500, 20000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries data or sequence data\n",
    "\n",
    "Whenever time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D tensor.\n",
    "\n",
    "<h4 align=\"center\">A 3D timeseries data tensor</h4> \n",
    "![time series tensor](img/3D_timeseries_tensor.jpeg)\n",
    "\n",
    "The time axis is always the second axis (axis of index 1), by convention. \n",
    "\n",
    "Examples:\n",
    "- **A dataset of stock prices.** Every minute, we store the current price of the stock, the highest price in the past minute, and the lowest price in the past minute. Thus every minute is encoded as a 3D vector, an entire day of trading is encoded as a 2D tensor of shape (390, 3) (there are 390 minutes in a trading day), and 250 days’ worth of data can be stored in a 3D tensor of shape (250, 390, 3). Here, each sample would be one day’s worth of data.\n",
    "\n",
    "- **A dataset of tweets**, where we encode each tweet as a sequence of 280 characters out of an alphabet of 128 unique characters. In this setting, each character can be encoded as a binary vector of size 128 (an all-zeros vector except for a 1 entry at the index corresponding to the character). Then each tweet can be encoded as a 2D tensor of shape (280, 128), and a dataset of 1 million tweets can be stored in a tensor of shape (1000000, 280, 128)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Image data\n",
    "\n",
    "Images typically have three dimensions: height, width, and color depth. Although grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a one-dimensional color channel for grayscale images.\n",
    "\n",
    "A batch of 128 grayscale images of size 256 × 256 could thus be stored in a tensor of shape (128, 256, 256, 1), and a batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3).\n",
    "\n",
    "<h4 align=\"center\">A 4D image data tensor</h4> \n",
    "![time series tensor](img/4D_image_tensor.jpeg)\n",
    "\n",
    "There are two conventions for shapes of images tensors:\n",
    "1. channels-last convention (used by TensorFlow) (samples, height, width, **color_depth**)\n",
    "2. channels-first convention (used by Theano) (samples, **color_depth**, height, width)\n",
    "\n",
    "Keras framework provides support for both formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video data\n",
    "\n",
    "Video data is one of the few types of real-world data for which you’ll need 5D tensors. A video can be understood as a sequence of frames, each frame being a color image. Because each frame can be stored in a 3D tensor (height, width, color_depth), a sequence of frames can be stored in a 4D tensor (frames, height, width, color_depth), and thus a batch of different videos can be stored in a 5D tensor of shape (-samples, frames, height, width, color_depth).\n",
    "\n",
    "For instance, a 60-second, 144 × 256 YouTube video clip sampled at 4 frames per second would have 240 frames. A batch of four such video clips would be stored in a tensor of shape (4, 240, 144, 256, 3). That’s a total of 106,168,320 values! If the dtype of the tensor was float32, then each value would be stored in 32 bits, so the tensor would represent 405 MB. Heavy! Videos you encounter in real life are much lighter, because they aren’t stored in float32, and they’re typically compressed by a large factor (such as in the MPEG format).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 The gears of neural networks: tensor operations\n",
    "\n",
    "In our initial example, we were building our network by stacking Dense layers on top of each other. This layer can be interpreted as a function, which takes as input a 2D tensor and returns another 2D tensor—a new representation for the input tensor.\n",
    "\n",
    "`keras.layers.Dense(512, activation='relu')`\n",
    "\n",
    "as \n",
    "\n",
    "output = relu(dot(W, input) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise operations\n",
    "\n",
    "The relu operation and addition are element-wise operations: operations that are applied independently to each entry in the tensors being considered. This means these operations are highly amenable to massively parallel implementations.\n",
    "\n",
    "In practice, when dealing with Numpy arrays, these operations are available as well-optimized built-in Numpy functions, which themselves delegate the heavy lifting to a Basic Linear Algebra Subprograms (BLAS) implementation.\n",
    "\n",
    "So, in Numpy, you can do the following element-wise operation, and it will be blazing fast:\n",
    "\n",
    "`z = x + y                   \n",
    "z = np.maximum(z, 0.)  `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "What happens with addition when the shapes of the two tensors being added differ?\n",
    "\n",
    "When possible, and if there’s no ambiguity, the smaller tensor will be *broadcasted* to match the shape of the larger tensor. Broadcasting consists of two steps:\n",
    "\n",
    "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor.\n",
    "\n",
    "With broadcasting, you can generally apply two-tensor element-wise operations if one tensor has \n",
    "\n",
    "shape (a, b, ... n, n + 1, ... m) and the other has \n",
    "\n",
    "shape (n, n + 1, ... m).\n",
    "\n",
    "The broadcasting will then automatically happen for axes athrough n - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "element-wise maximum operation to two tensors of different shapes via broadcasting\n",
    "'''\n",
    "x = np.random.random((64, 3, 32, 10))        \n",
    "y = np.random.random((32, 10))               \n",
    "z = np.maximum(x, y)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor dot\n",
    "\n",
    "The dot operation, also called a tensor product is the most common, most useful tensor operation. Contrary to element-wise operations, it combines entries in the input tensors.\n",
    "\n",
    "in Numpy, Keras, Theano, and TensorFlow,\n",
    "\n",
    "An element-wise product is done with the \\* operator \n",
    "\n",
    "`dot` uses a different syntax in TensorFlow, but in both Numpy and Keras it’s done using the standard dot operator\n",
    "\n",
    "`z = np.dot(x, y)`\n",
    "\n",
    "in math notation,\n",
    "z = x . y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor reshaping\n",
    "\n",
    "we used it when we preprocessed the digits data before feeding it into our network:\n",
    "`train_images = train_images.reshape((60000, 28 * 28))`\n",
    "\n",
    "Reshaping a tensor means rearranging its rows and columns to match a target shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "                 [2., 3.],\n",
    "                 [4., 5.]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of reshaping that’s commonly encountered is transposition. **Transposing** a matrix means exchanging its rows and its columns, so that x[i, :]becomes x[:, i]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300, 20))  \n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric interpretation of tensor operations\n",
    "\n",
    "Because the contents of the tensors manipulated by tensor operations can be interpreted as coordinates of points in some geometric space, all tensor operations have a geometric interpretation.\n",
    "\n",
    "<h4 align=\"center\">A point in a 2D space</h4> \n",
    "![time series tensor](img/geo1.jpeg)\n",
    "\n",
    "<h4 align=\"center\">A point in a 2D space pictured as an arrow</h4> \n",
    "![time series tensor](img/geo2.jpeg)\n",
    "\n",
    "<h4 align=\"center\">Geometric interpretation of the sum of two vectors</h4> \n",
    "![time series tensor](img/geo3.jpeg)\n",
    "\n",
    "\n",
    "In general, elementary geometric operations such as affine transformations, rotations, scaling, and so on can be expressed as tensor operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A geometric interpretation of deep learning\n",
    "\n",
    "Neural networks consist entirely of chains of tensor operations and that all of these tensor operations are just geometric transformations of the input data. It follows that you can interpret a neural network as a very complex geometric transformation in a high-dimensional space, implemented via a long series of simple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The engine of neural networks: gradient-based optimization\n",
    "\n",
    "output = relu(dot(W, input) + b)\n",
    "\n",
    "W and b are tensors that are attributes of the layer. They’re called the weights or trainable parameters of the layer. Initially, these weight matrices are filled with small random values What comes next is to gradually adjust these weights, based on a feedback signal. This gradual adjustment, also called training, is basically the learning that machine learning is all about.\n",
    "\n",
    "**training loop**\n",
    "1. Draw a batch of training samples x and corresponding targets y.\n",
    "2. Run the network on x (a step called the forward pass) to obtain predictions y_pred.\n",
    "3. Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y.\n",
    "4. Update all weights of the network in a way that slightly reduces the loss on this batch.\n",
    "\n",
    "\n",
    "You’ll eventually end up with a network that has a very low loss on its training data: a low mismatch between predictions y_pred and expected targets y.\n",
    "\n",
    "The difficult part is step 4: updating the network’s weights. Given an individual weight coefficient in the network, how can you compute whether the coefficient should be increased or decreased, and by how much?\n",
    "\n",
    "We can take advantage of the fact that all operations used in the network are differentiable, and compute the gradient of the loss with regard to the network’s coefficients. You can then move the coefficients in the opposite direction from the gradient, thus decreasing the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What’s a derivative?\n",
    "\n",
    "Consider a continuous, smooth function `f(x) = y`, mapping a real number `x` to a new real number `y`. Because the function is continuous, a small change in x can only result in a small change in y.\n",
    "\n",
    "`f(x + epsilon_x) = y + epsilon_y`\n",
    "\n",
    "In addition, because the function is smooth, when `epsilon_x` is small enough, around a certain point `p`, it’s possible to approximate `f` as a linear function of slope `a`, so that `epsilon_y` becomes `a * epsilon_x`.\n",
    "\n",
    "`f(x + epsilon_x) = y + a * epsilon_x`\n",
    "\n",
    "The slope a is called the derivative of f in p.\n",
    "\n",
    "<h4 align=\"center\">Derivative of f in p</h4> \n",
    "![time series tensor](img/derivative.jpeg)\n",
    "\n",
    "For every differentiable function `f(x)`, there exists a derivative function `f'(x)` that maps values of `x` to the slope of the local linear approximation of `f` in those points.\n",
    "\n",
    "If you’re trying to update x by a factor epsilon_x in order to minimize f(x), and you know the derivative of f, then your job is done: the derivative completely describes how f(x) evolves as you change x. If you want to reduce the value of f(x), you just need to move x a little in the opposite direction from the derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative of tensor operation: the gradient\n",
    "\n",
    "A **gradient** is the derivative of a tensor operation. It’s the generalization of the concept of derivatives to functions of multidimensional inputs: that is, to functions that take tensors as inputs.\n",
    "\n",
    "Consider input vector x, a matrix W, a target y, and a loss function.\n",
    "Use W to compute a target candidate y_pred, and compute the loss between the target candidate y_pred and the target y.\n",
    "\n",
    "`y_pred = dot(W, x)\n",
    "loss_value = loss(y_pred, y)\n",
    "`\n",
    "\n",
    "If the data inputs x and y are frozen, then this can be interpreted as a function mapping values of W to loss values:\n",
    "\n",
    "`loss_value = f(W)`\n",
    "\n",
    "Let’s say the current value of W is W0.\n",
    "\n",
    "Derivative of f in the point W0 is a tensor gradient(f)(W0).\n",
    "\n",
    "Gradient(f)(W0) can be interpreted as the tensor describing the *curvature* of f(W) around W0.\n",
    "\n",
    "For this reason, in much the same way that, for a function f(x), you can reduce the value of f(x) by moving x a little in the opposite direction from the derivative, with a function f(W) of a tensor, you can reduce f(W) by moving W in the opposite direction from the gradient. Going against the curvature should put you lower on the curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "Given a differentiable function, it’s theoretically possible to find its minimum analytically: it’s known that a function’s minimum is a point where the derivative is 0.\n",
    "\n",
    "Applied to a neural network, that means finding analytically the combination of weight values that yields the smallest possible loss function. This can be done by solving the equation gradient(f)(W) = 0 for W. \n",
    "\n",
    "We use the four-step algorithm. We modify the parameters little by little based on the current loss value on a random batch of data. Because we're dealing with a differentiable function, we can compute its gradient to efficiently do part 4.\n",
    "\n",
    "#### mini-batch stochastic gradient descent (mini-batch SGD)\n",
    "\n",
    "1. Draw a batch of training samples x and corresponding targets y.\n",
    "2. Run the network on x to obtain predictions y_pred.\n",
    "3. Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y.\n",
    "4. Compute the gradient of the loss with regard to the network’s parameters (a backward pass).\n",
    "5. Move the parameters a little in the opposite direction from the gradient—for example W = step * gradient—thus reducing the loss on the batch a bit.\n",
    "\n",
    "<h4 align=\"center\">SGD down a 1D loss curve (one learnable parameter)</h4> \n",
    "![time series tensor](img/sgd.jpeg)\n",
    "\n",
    "We can see that it’s important to pick a reasonable value for the stepfactor.\n",
    "\n",
    "single sample - true SGD\n",
    "run every step on all data available - batch SGD\n",
    "compromise between these two - mini-batch\n",
    "\n",
    "In practice you’ll use gradient descent in highly dimensional spaces: every weight coefficient in a neural network is a free dimension in the space, and there may be tens of thousands or even millions of them.\n",
    "\n",
    "<h4 align=\"center\">Gradient descent down a 2D loss surface (two learnable parameters)</h4> \n",
    "![time series tensor](img/sgd2d.jpeg)\n",
    "\n",
    "There exist multiple variants of SGD that differ by taking into account previous weight updates when computing the next weight update, rather than just looking at the current value of the gradients. SGD with momentum, as well as Adagrad, RMSProp, and several others. Such variants are known as *optimization methods or optimizers*.\n",
    "\n",
    "The concept of **momentum**, which is used in many of these variants, deserves your attention. Momentum addresses two issues with SGD: \n",
    "1. Convergence speed\n",
    "2. Local minima\n",
    "\n",
    "<h4 align=\"center\">A local minimum and a global minimum</h4> \n",
    "![time series tensor](img/momentum.jpeg)\n",
    "\n",
    "If the parameter under consideration were being optimized via SGD with a small learning rate, then the optimization process would get stuck at the local minimum instead of making its way to the global minimum.\n",
    "\n",
    "You can avoid such issues by using **momentum**.\n",
    "Think of the optimization process as a small ball rolling down the loss curve. If it has enough momentum, the ball won’t get stuck in a ravine and will end up at the global minimum. Momentum is implemented by moving the ball at each step based not only on the current slope value (current acceleration) but also on the current velocity (resulting from past acceleration). In practice, this means updating the parameter w based not only on the current gradient value but also on the previous parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining derivatives: the Backpropagation algorithm\n",
    "\n",
    "Calculus chain rule: `f(g(x)) = f'(g(x)) * g'(x)`\n",
    "\n",
    "Applying the chain rule to the computation of the gradient values of a neural network gives rise to an algorithm called **Backpropagation**.\n",
    "\n",
    "Now, frameworks are capable of symoblic differentiation (TensorFlow), meaning that given a chain of operations with a known derivative, they can compute a gradient function for the chain (by applying the chain rule) that maps network parameter values to gradient values. We don't have to implement backprop by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Takeaways\n",
    "\n",
    "- **Learning** means finding a combination of model parameters that minimizes a *loss function* for a given set of training data samples and their corresponding targets.\n",
    "- Learning happens by drawing random batches of data samples and their targets, and computing the gradient of the network parameters with respect to the loss on the batch. The network parameters are then moved a bit (magnitude defined by learning rate) in the opposite direction from the gradient.\n",
    "- Entire learning process of is possible b/c neural nets are chains of differentiable tensor operations and so we can apply *chain rule* of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value.\n",
    "- 2 key concepts: **loss** and **optimizers**. These need to be defined before feeding data into network.\n",
    "- **optimizer** specifies the exact way in which gradient of the loss will be used to update parameters. (ie RMSProp, SGD with momentum, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
